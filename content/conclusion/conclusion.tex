\chapter{Conclusion}
The goal of the thesis was to explore different feature extraction and classification techniques, which can be used for visual signals, i.e. images, classification. In the first part of the thesis, we introduced such techniques. In the next part of the thesis, we introduced three progressively complex datasets.

We attempted to classify these datasets, after reducing their dimension by applying different feature extraction techniques, using different classifiers. In the final part of the thesis, we show the results of this classification.

For the feature extraction, we make use of a global feature extractor, i.e. PCA, and three local feature extractors, namely SIFT, SURF, and ORB. The classification itself was carried out by the SVM model and the Bayesian model classifiers. We used a numerical solution of the Bayesian model applying the Spectral Projected Gradient method, and an analytical solution of the model exploiting the Jensen inequality.

We started by applying this classification pipeline to the simplest dataset, i.e. the dataset of images of 2D shapes. Afterward, we moved onto a more complex dataset of images of 3D shapes. The last dataset we attempt to classify is the most complex Cats and Dogs dataset.

We run our experiments on the Salomon supercomputer at IT4Innovations. The analytical solution of the Bayesian model classifier was the fastest to train while providing similar classification results to the SVM model in most cases. While feature extraction using the SURF extractor was always the fastest, the classification of such data led to worse results than the classification of the data extracted by SIFT or ORB. While the use of SIFT and ORB lead usually to similar classification results, ORB had the advantage of lower time complexity. In our experiments, the data extracted using PCA was not suitable for the classification.

The advantage of our approach to the classification problem, over the more popular neural networks, is our ability to understand and examine each step, and each parameter of each step. In the future, the hyperparameter optimization could be applied to the whole pipeline, from the extractor to the classifier parameters. It might also be beneficial to test different optimization algorithms in the SVM, allowing for faster convergence.
